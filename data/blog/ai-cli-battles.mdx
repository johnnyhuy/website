---
title: AI CLI Battles
summary: |
  Comparing three AI CLI tools: Claude Code (powerful but $10-15/PR), OpenAI's Codex CLI (open-source but inconsistent), and Amazon Q Developer (enterprise-focused but opaque). All use "soft-cache" codebase understanding. Real-world usage shows promise but requires human oversight—we're moving from precise commands to AI collaboration in terminals.
date: "2025-05-25 07:20:00 +1000"
tags:
  - ai
  - developer-experience
draft: false
---

The familiar hum of terminal sessions has taken on a new character lately. Where once we typed precise commands with surgical accuracy, developers are now conversing with their command line in plain English. What sounds revolutionary is actually the maturation of an idea that's been brewing since the early days of GPT-3.5[^1].

Cast your mind back to the early days of 2023—light years ago in AI time. While everyone was marvelling at ChatGPT's conversational abilities, a handful of developers were asking a more ambitious question: what if we could delegate entire tasks to AI agents through the command line? [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)[^2] emerged as the proof of concept, a scrappy tool that demonstrated the tantalising possibility of autonomous AI agents executing complex development workflows.

The concept was brilliant in its simplicity: give an AI agent a goal, let it break down the task, execute commands, and iterate until completion. But like many pioneering technologies, AutoGPT was more proof-of-concept than production-ready tool. The foundation models weren't quite there yet, the tooling was rough around the edges, and the developer experience left much to be desired.

Now, as the industry reaches critical mass, major vendors are presenting their refined versions of this same core concept. The question isn't whether AI-powered CLI tools will transform development workflows—it's which approach will define the next decade of software engineering.

## CLI Tools

### Claude Code

[Claude Code](https://www.anthropic.com/claude-code)[^3] represents Anthropic's vision of an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows through natural language commands. What sets it apart isn't just its technical capabilities, but its philosophical approach to developer autonomy.

The tool excels in several key areas:

- **Codebase Intelligence**: Claude Code maps and explains entire codebases in a few seconds, using agentic search to understand project structure and dependencies without manual context selection. This "soft-cache" approach—essentially generating markdown documentation that explains your codebase—has become a defining pattern across AI CLI tools.

- **IDE Integration**: Rather than forcing developers to abandon their preferred environments, Claude Code offers extensions for VS Code, JetBrains, and Neovim. These extensions bridge the gap between terminal-based AI assistance and the rich context available through IDE APIs.

- **Model Flexibility**: Support for Anthropic's full model suite, plus integration with Amazon Bedrock and Google Cloud Vertex AI, makes it enterprise-ready without vendor lock-in concerns.

- **Thinking Modes**: Claude Code includes specific phrases that trigger extended thinking modes—"think" provides 4,000 tokens of thinking budget, while "ultrathink" allocates up to 31,999 tokens for complex reasoning[^4].

The downside? Cost and accessibility. API costs for a medium-sized PR typically range from $10-15[^5], making it a significant investment for frequent use.

### OpenAI's Codex CLI

[OpenAI's Codex CLI](https://github.com/openai/codex)[^6] takes a different approach—it's designed to give users a minimal, transparent interface to link models directly with code and tasks. This represents a strategic shift for OpenAI, moving from closed platforms to community-driven development[^7].

Key differentiators include:

- **Open Source Philosophy**: Unlike Claude Code's closed-source approach, Codex CLI allows community contributions and customisation. This could prove crucial for adoption in enterprise environments where transparency and auditability matter.

- **Model Integration**: Support for any model available through the Responses API, with o4-mini as default but configurable to gpt-4.1 or other models.

- **Sandbox Execution**: Codex runs model-generated commands in a sandbox, allowing developers to review and approve changes before execution.

Early comparisons suggest performance differences. One developer noted that "Claude Code did great and wrote pretty decent docs, while Codex didn't do well—it hallucinated a bunch of stuff that wasn't in the code and completely misrepresented the architecture"[^8].

### Amazon Q Developer CLI

Amazon's entry into this space reflects their cloud-first, enterprise-focused philosophy. The tool integrates deeply with AWS services but suffers from what I'd call "enterprise bloat"—requiring a desktop application for configuration and complex OAuth flows through IAM Identity Centre.

> [!WARNING]
> The concerning aspect is the proprietary model approach, I'm going to safely assume they're using Claude Sonnet 3.7 or 4. Without transparency into the underlying foundation models, developers face context management uncertainties.
> 
> Large companies like Amazon struggle to keep pace with the rapid evolution of LLM capabilities, potentially leaving users with outdated reasoning abilities compared to the cutting-edge models powering Claude Code or Codex CLI.

Ultimately, I do have my own bias towards self-hosting and homelabbing, but I do see value in enterprises like Amazon throwing money at this space to provide a more enterprise-grade experience.

## Contextual Codebase Understanding

Across all these tools, one pattern emerges consistently: the `/init` command or equivalent functionality that helps the AI understand your codebase. This represents a fundamental shift in how we think about development environments.

The process is surprisingly straightforward:
1. The AI agent scans your project structure
2. It greps through code to understand patterns and dependencies  
3. It generates a comprehensive markdown document explaining the codebase
4. This documentation becomes the foundation for all subsequent interactions

What's particularly clever is that this "soft-cache" can be portable between tools. You can use Claude Code to generate initial codebase documentation, then leverage that same understanding with OpenAI's Codex CLI or other tools. The pattern isn't proprietary—it's a natural evolution of how AI agents need to contextualise large codebases.

## The IDE Integrations

The boundary between CLI-based AI tools and IDE-embedded assistants is increasingly blurred. Tools like Windsurf, Cursor, and GitHub Copilot all offer "agent modes" that essentially perform the same codebase analysis and command execution as their CLI counterparts.

Claude Code supports both Amazon Bedrock and Google Vertex AI, making it enterprise ready without egress to external vendors. Meanwhile, IDE-based solutions offer tighter integration with development workflows but less flexibility in execution environments.

The choice between CLI and IDE integration often comes down to developer preferences and team workflows. CLI tools offer more control and transparency, while IDE integrations provide seamless context switching and visual feedback.

## MCP

The [Model Control Protocol (MCP)](https://modelcontextprotocol.io/)[^9] represents a crucial development in this space. All these CLI tools can use MCP to a degree, opening opportunities to search with engines like [Perplexity](https://www.perplexity.ai/), query databases like [PostgreSQL](https://www.postgresql.org/), or interact with task management platforms like [Jira](https://www.atlassian.com/software/jira) or [Linear](https://linear.app/).

This standardisation effort means that AI agents aren't limited to basic file operations and command execution. They can integrate with the full ecosystem of development tools, from version control to project management to deployment pipelines.

Say I want to query technical documentation on the internet, I can simply add the fetch MCP to my relevant CLI tool. From there I can ask the same question and I'll get a tool call to the MCP server to fetch the relevant documentation.

## Promises vs Reality

The marketing materials paint an impressive picture, but real-world usage reveals important nuances. One developer spent a week with Claude Code on Clojure projects, investing $134.79 and 12 hours, ultimately concluding that "[Cursor](https://cursor.sh/) is a much better workflow for me" and that "AI without oversight is still not there to deliver maintainable apps"[^10].

This highlights a crucial reality: these tools excel at the "first 90%" of development tasks but struggle with the "second 90%"—the refinement, debugging, and maintenance that transforms prototypes into production-ready applications.

Another developer noted the importance of defensive coding practices: "Building in the practice to run the linter constantly has kept a lot of bugs away... Add in a good formatter and everything is beautiful. The real magic is to add these tasks to a pre-commit hook"[^11].

One of the biggest "aha" moment for me was using Windsurf, dragging and dropping image files into the chat. It then used Puppeteer to navigate to the image and screen scrape the relevant information. It then used that information to generate a prompt for the AI to generate the code. Not sure if that's possible in an CLI, but it's the kind of tooling that I think will be game changing.

## Trust But Verify

One persistent challenge across all AI CLI tools is the hallucination problem. Even sophisticated models can misread documentation, miss crucial context, or suggest solutions based on outdated information. The key is ensuring relevant tools are enabled to allow web requests for technical documentation and confirming whether the AI actually read linked content.

This creates an interesting paradox: the more autonomous we make these tools, the more critical human oversight becomes. The most successful implementations seem to involve active collaboration rather than passive delegation, which these tools encourage you to do.

## The Developer Experience

We're witnessing what I call the "developer experience arms race." Each tool borrows ideas from competitors in a tit-for-tat evolution of features. The determining factors will ultimately be:

1. **LLM Performance**: The quality of the underlying reasoning models
2. **Tool Ergonomics**: How well the interface fits existing developer workflows
3. **Transparency**: Whether developers can trust and verify the AI's actions
4. **Cost Structure**: Sustainable pricing for frequent use

Companies like [Cursor](https://cursor.sh/), [Cognition](https://www.cognition-labs.com/), [Vercel](https://vercel.com/), [Replit](https://replit.com/), and [Canva](https://www.canva.com/) have rigorously tested Claude's capabilities, reporting significant improvements in tool execution, production-ready code generation, and debugging efficiency[^12].

## Looking Forward: Beyond the Hype Cycle

As someone who's watched developer tools evolve for over a decade, I see striking parallels to the early days of containerisation. [Docker](https://www.docker.com/)[^13] seemed magical initially—a universal solution to deployment complexity. But the real value emerged through the ecosystem that developed around it: orchestration platforms, service meshes, and cloud-native architectures.

AI CLI tools are following a similar trajectory. The initial wow factor of natural language programming is giving way to more nuanced understanding of where these tools excel and where human expertise remains irreplaceable.

The most successful teams will likely adopt a hybrid approach:
- Use AI CLI tools for rapid prototyping and routine tasks
- Maintain human oversight for architectural decisions and complex debugging
- Implement robust testing and validation workflows to catch AI-generated errors
- Develop team practices around prompt engineering and AI tool management

## The Paradox of Choice

Developers are now spoiled for choice when it comes to AI-powered development tools. The question isn't whether to adopt these technologies—it's which combination of tools provides the best fit for your specific context.

Consider your development environment:
- **For rapid prototyping**: Claude Code's comprehensive codebase understanding shines
- **For cost-conscious teams**: OpenAI's Codex CLI offers open-source flexibility
- **For enterprise environments**: Amazon Q Developer provides AWS integration at the cost of transparency
- **For IDE-centric workflows**: Cursor, Windsurf, or GitHub Copilot might be more natural fits

The key insight is that this isn't a zero-sum game. The underlying patterns—codebase contextualisation, natural language interfaces, and agentic task delegation—are becoming table stakes across the industry.

## Bottom Line

The AI CLI change represents more than just new tools—it's a fundamental shift in how we interact with code and development environments. The dream of conversational programming, first glimpsed in AutoGPT's experimental days, is becoming production reality.

But like all transformative technologies, the real value lies not in replacing human expertise but in amplifying it. The developers who thrive in this new landscape will be those who learn to collaborate effectively with AI agents while maintaining the critical thinking and architectural vision that defines great software engineering.

The terminal session has evolved from a place of precise commands to a space of collaborative problem-solving. The question now is whether we're ready to embrace this new partnership between human creativity and artificial intelligence.

What's your experience with AI CLI tools? Are you seeing similar patterns in your development workflows, or have you discovered approaches that work better for your specific context?

---

## References

[^1]: The GPT-3.5 model was released by OpenAI in March 2022, setting the foundation for autonomous AI agent development that culminated in tools like AutoGPT.

[^2]: [AutoGPT GitHub Repository](https://github.com/Significant-Gravitas/AutoGPT) - The original autonomous AI agent that demonstrated task delegation capabilities.

[^3]: [Claude Code Official Documentation](https://www.anthropic.com/claude-code) - Anthropic's comprehensive CLI coding assistant.

[^4]: [Claude Code Best Practices - Thinking Modes](https://simonwillison.net/2025/Apr/19/claude-code-best-practices/) - Simon Willison's analysis of Claude Code's thinking budget allocation system.

[^5]: [OpenAI Codex CLI vs Claude Code Comparison](https://dev.to/czmilo/whats-openai-codex-cliand-compare-with-claude-codeaidercursorwindsurf-121p) - Cost analysis and feature comparison between major AI CLI tools.

[^6]: [OpenAI Codex CLI GitHub Repository](https://github.com/openai/codex) - OpenAI's open-source terminal-based coding agent.

[^7]: [TechCrunch: OpenAI debuts Codex CLI](https://techcrunch.com/2025/04/16/openai-debuts-codex-cli-an-open-source-coding-tool-for-terminals/) - Coverage of OpenAI's $1 million grant initiative for Codex CLI projects.

[^8]: [Hacker News Discussion: OpenAI Codex CLI](https://news.ycombinator.com/item?id=43708025) - Community feedback comparing Claude Code and Codex CLI performance.

[^9]: [Model Control Protocol Introduction](https://modelcontextprotocol.io/) - Official documentation for the MCP standard that enables AI tool integration.

[^10]: [Flexiana: Experience with Claude Code](https://flexiana.com/news/2025/03/experience-with-claude-code) - Real-world case study of Claude Code usage over one week with detailed cost and time analysis.

[^11]: [Harper Reed: Basic Claude Code](https://harper.blog/2025/05/08/basic-claude-code/) - Practical workflow tips and defensive coding strategies for AI CLI tools.

[^12]: [Anthropic: Claude Code Overview](https://www.anthropic.com/claude-code) - Customer testimonials and performance data from enterprise users.

[^13]: [Docker Official Website](https://www.docker.com/) - The containerisation platform that transformed software deployment practices.